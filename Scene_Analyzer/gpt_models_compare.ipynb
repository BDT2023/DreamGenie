{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from my_secrets import API_KEY_OPENAI\n",
    "import tiktoken\n",
    "import textwrap\n",
    "import os\n",
    "from gpt_call import separate\n",
    "\n",
    "openai.api_key = API_KEY_OPENAI\n",
    "PRICES = {\"text-curie-001\":(0.0020 / 1000),\"text-davinci-003\":(0.020 / 1000)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to test how feasible it is to pass manually separated scenes as part of the prompt to GPT3.\n",
    "One of the concerns is that the model might not be able to generate a coherent scene if the prompt is too short. We would like to test this by comparing the performance of GPT3 with and without a prompt. In addition, adding more text to the prompt adds cost to the API call, so we would like to test how much text is needed to get a good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compare the output of two models on the same input, so we'll use the same dream for both.\n",
    "models = [\"text-curie-001\",\"text-davinci-003\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_samples():\n",
    "    \"\"\"\n",
    "    Open the file with the manually separated scenes and return a list of the separated dreams.\n",
    "    \"\"\"\n",
    "    with open(\"manual_scene_separation_data.txt\", \"r\") as f:\n",
    "        data = f.read()\n",
    "        samples = data.split(\"###\")[1:-1]\n",
    "        counter = 1\n",
    "        temp = []\n",
    "        for counter,s in enumerate(samples):\n",
    "            s = s.replace(\"IN:\", \"\").strip()\n",
    "            temp.append(s)\n",
    "            #print(s)\n",
    "            counter+=1\n",
    "        return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random dream description from the excel file(dream corpus)\n",
    "dream = separate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "command=\"Give short visual descriptions of the scenes in the following:\"\n",
    "examples = \"\"\n",
    "samples = get_samples()\n",
    "n = 0 # number of examples of manual separation to pass to the model\n",
    "for i in range(0,min(len(samples),n)):\n",
    "    examples+=samples[i]\n",
    "    examples+=os.linesep\n",
    "#print(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are passing examples in the prompt, we need to add \"Examples:\" to the prompt, otherwise we don't.\n",
    "if examples!=\"\":\n",
    "    prompt = (f\"{command}{os.linesep}Examples:\\\n",
    "{examples.strip()}\\\n",
    "{dream}\") \n",
    "else:\n",
    "    prompt = (f\"{command}{os.linesep}{dream}\")\n",
    "#print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_price(model, prompt):   \n",
    "    # Use the tiktoken library to tokenize the prompt and calculate the price accordingly.\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(prompt))\n",
    "    return num_tokens * PRICES[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(prompt, generated_text,model,price):\n",
    "    with open(\"compare_out.txt\", \"a+\") as f:\n",
    "        f.write(f'#Model:{model}, price:{round(price,5)}$ with {n} examples')\n",
    "        f.write(os.linesep)\n",
    "        f.write(f'#Prompt:{os.linesep}{prompt.split(\"Examples:\")[0]}')\n",
    "        f.write(f'{dream}')\n",
    "        f.write(os.linesep)\n",
    "        f.write(f'#Output: {os.linesep}{generated_text}')\n",
    "        f.write(os.linesep)\n",
    "        f.write(f'########################')\n",
    "        f.write(os.linesep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    prompt_price = calc_price(m, prompt)\n",
    "    completions = openai.Completion.create(\n",
    "        engine=m,\n",
    "        prompt=prompt,\n",
    "        max_tokens=512,\n",
    "        n=1,\n",
    "        stop=None, #optional token that stops the generation\n",
    "        temperature=0.45, # not too high\n",
    "    )\n",
    "    generated_text = completions.choices[0].text\n",
    "    gen_price = calc_price(m, generated_text)\n",
    "    write_to_file(prompt, generated_text, m, prompt_price+gen_price)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generated_text)\n",
    "# write_to_file(prompt, generated_text, m, prompt_price+gen_price)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
