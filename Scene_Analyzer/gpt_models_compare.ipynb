{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from my_secrets import API_KEY_OPENAI\n",
    "import tiktoken\n",
    "import textwrap\n",
    "import os\n",
    "from gpt_call import separate\n",
    "\n",
    "openai.api_key = API_KEY_OPENAI\n",
    "PRICES = {\"text-curie-001\":(0.0020 / 1000),\"text-davinci-003\":(0.020 / 1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"text-curie-001\",\"text-davinci-003\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    with open(\"manual_scene_separation_data.txt\", \"r\") as f:\n",
    "        data = f.read()\n",
    "        samples = data.split(\"###\")[1:-1]\n",
    "        counter = 1\n",
    "        temp = []\n",
    "        for counter,s in enumerate(samples):\n",
    "            s = s.replace(\"IN:\", \"\").strip()\n",
    "            temp.append(s)\n",
    "            #print(s)\n",
    "            counter+=1\n",
    "        return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = separate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "command=\"Give short visual descriptions of the scenes in the following:\"\n",
    " # get a dream from the dream corpus\n",
    "examples = \"\"\n",
    "samples = get_samples()\n",
    "n = 0 # number of examples to use\n",
    "for i in range(0,min(len(samples),n)):\n",
    "    examples+=samples[i]\n",
    "    examples+=os.linesep\n",
    "#print(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "if examples!=\"\":\n",
    "    prompt = (f\"{command}{os.linesep}Examples:\\\n",
    "{examples.strip()}\\\n",
    "{dream}\") \n",
    "else:\n",
    "    prompt = (f\"{command}{os.linesep}{dream}\")\n",
    "#print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_price(model, prompt):   \n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(prompt))\n",
    "    return num_tokens * PRICES[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(prompt, generated_text,model,price):\n",
    "    with open(\"compare_out.txt\", \"a+\") as f:\n",
    "        f.write(f'#Model:{model}, price:{round(price,5)}$ with {n} examples')\n",
    "        f.write(os.linesep)\n",
    "        f.write(f'#Prompt:{os.linesep}{prompt.split(\"Examples:\")[0]}')\n",
    "        f.write(f'{dream}')\n",
    "        f.write(os.linesep)\n",
    "        f.write(f'#Output: {os.linesep}{generated_text}')\n",
    "        f.write(os.linesep)\n",
    "        f.write(f'########################')\n",
    "        f.write(os.linesep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    prompt_price = calc_price(m, prompt)\n",
    "    completions = openai.Completion.create(\n",
    "        engine=m,\n",
    "        prompt=prompt,\n",
    "        max_tokens=512,\n",
    "        n=1,\n",
    "        stop=None, #optional token that stops the generation\n",
    "        temperature=0.45, # not too high\n",
    "    )\n",
    "    generated_text = completions.choices[0].text\n",
    "    gen_price = calc_price(m, generated_text)\n",
    "    write_to_file(prompt, generated_text, m, prompt_price+gen_price)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generated_text)\n",
    "# write_to_file(prompt, generated_text, m, prompt_price+gen_price)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
