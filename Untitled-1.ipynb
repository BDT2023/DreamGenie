{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def RMSE(test_set,cf):\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    rmse = mean_squared_error(np.array(test_set['Rating']),\n",
    "                              np.array([cf.pred.at[row] for row in zip(test_set['UserId'],test_set['ProductId'])]),\n",
    "                              squared = False).round(5)\n",
    "    rmse_bench = mean_squared_error(np.array(test_set['Rating']),np.array(\n",
    "        [cf.mean_matrix.at[row] for row in zip(test_set['UserId'],test_set['ProductId'])]),squared = False).round(5)\n",
    "    #np.sqrt(mean_squared_error(test_set['Rating'],cf.pred.loc[test_set['UserId'],test_set['ProductId']]))\n",
    "    print(f'RMSE for {cf.strategy} based is: {rmse}')\n",
    "    print(f'RMSE for benchmark is: {rmse_bench}')\n",
    "\n",
    "def precision_at_k(test_set,cf,k):\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    relevant_items = test_set[test_set['Rating'] > 3]\n",
    "    precision_alt = np.mean(\n",
    "        [len(pd.Index(relevant_items['ProductId']).intersection(cf.recommend_items(user,k = k))) / k for user in\n",
    "         relevant_items['UserId'].unique()])\n",
    "    print(f'Precision at {k} is {precision_alt}')\n",
    "\n",
    "    bench = cf.user_item_matrix.mean(axis = 0).sort_values(ascending = False)[:k]\n",
    "    precision_bench = [len(pd.Index(relevant_items['ProductId']).intersection(bench.index)) / k for _ in\n",
    "                       relevant_items['UserId'].unique()]\n",
    "    print(f'Precision at {k} for benchmark is {np.mean(precision_bench)}')\n",
    "\n",
    "def recall_at_k(test_set,cf,k):\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    relevant_items = test_set[test_set['Rating'] > 3]\n",
    "    recall = np.mean(\n",
    "        [len(pd.Index(relevant_items['ProductId']).intersection(cf.recommend_items(user,k = k))) / len(relevant_items)\n",
    "         for user in relevant_items['UserId'].unique()])\n",
    "    print(f'recall at {k} is {recall}')\n",
    "\n",
    "    bench = cf.user_item_matrix.mean(axis = 0).sort_values(ascending = False)[:k]\n",
    "    recall_bench = [len(pd.Index(relevant_items['ProductId']).intersection(bench.index)) / len(relevant_items) for _ in\n",
    "                       relevant_items['UserId'].unique()]\n",
    "    print(f'recall at {k} for benchmark is {np.mean(recall_bench)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37f3578b87c31b783d1ad88d8b899f16482ddf7675847c0e65d4369918cd551c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
